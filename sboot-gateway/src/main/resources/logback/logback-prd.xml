<?xml version="1.0" encoding="UTF-8"?>
<!--scan自动扫描重新加载配置 scanPeriod重新加载配置的周期-->
<configuration debug="true" scan="true" scanPeriod="10 seconds">

	<contextName>${spring.application.name}</contextName>
	<!--定义参数,后面可以通过${app.name}使用-->
	<!--<property name="app-name" value="provider"/>-->

	<!--凡是springProperty的配置都将出现在生成的json中，如果原json中已有相同key则将覆盖-->
	<springProperty scope="context" name="spring.application.name" source="spring.application.name"/>
	<springProperty scope="context" name="server.port" source="server.port"/>
	<springProperty scope="context" name="logstash.server-addr" source="logstash.server-addr"/>
	<springProperty scope="context" name="log.level" source="log.level"/>
	<springProperty scope="context" name="log.path" source="log.path"/>

	<appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
		<destination>${logstash.server-addr}</destination>
		<!-- encoder必须配置,有多种可选 -->
		<encoder charset="UTF-8" class="net.logstash.logback.encoder.LogstashEncoder">
			<!--在生成的json中会加这个字段-->
			<!--<customFields>{"appname":"${spring.application.name}"}</customFields>-->
		</encoder>
		<filter class="ch.qos.logback.classic.filter.ThresholdFilter">
			<level>${log.level}</level>
		</filter>
		<connectionStrategy>
			<roundRobin>
				<!-- 轮询时间间隔-->
				<connectionTTL>5 minutes</connectionTTL>
				<!--<connectionTTL>5 seconds</connectionTTL>-->
			</roundRobin>
		</connectionStrategy>
	</appender>

	<appender name="file" class="ch.qos.logback.core.rolling.RollingFileAppender">
		<filter class="ch.qos.logback.classic.filter.ThresholdFilter">
			<level>${log.level}</level>
		</filter>
		<!--定义日志输出的路径-->
		<!--通过 java -Dscheduler.manager.server.home=/path/to XXXX 配置该属性-->
		<file>${log.path}/${spring.application.name}.log</file>
		<!--定义日志滚动的策略-->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<!--定义文件滚动时的文件名的格式-->
			<fileNamePattern>
				${log.path}/${spring.application.name}.%d{yyyy-MM-dd.HH}.log.gz
			</fileNamePattern>
			<!--60天的时间周期，日志量最大20GB-->
			<maxHistory>60</maxHistory>
			<!-- 该属性在 1.1.6版本后 才开始支持-->
			<totalSizeCap>20GB</totalSizeCap>
		</rollingPolicy>
		<triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">
			<!--每个日志文件最大100MB-->
			<maxFileSize>100MB</maxFileSize>
		</triggeringPolicy>
		<!--定义输出格式-->
		<encoder>
			<pattern>%red(%d{yyyy-MM-dd HH:mm:ss}) %green([%thread]) %highlight(%-5level) %boldMagenta(%logger{10}) - %cyan(%msg%n)</pattern>
		</encoder>
	</appender>

	<root level="info">
		<appender-ref ref="LOGSTASH"/>
		<appender-ref ref="file"/>
	</root>

	<!--对于类路径以 com.example.logback 开头的Logger,输出级别设置为warn,并且只输出到控制台-->
	<!--这个logger没有指定appender，它会继承root节点中定义的那些appender-->
	<!--<logger name="com.example.logback" level="warn"/>-->

	<!--通过 LoggerFactory.getLogger("mytest") 可以获取到这个logger-->
	<!--由于这个logger自动继承了root的appender，root中已经有stdout的appender了，自己这边又引入了stdout的appender-->
	<!--如果没有设置 additivity="false" ,就会导致一条日志在控制台输出两次的情况-->
	<!--additivity表示要不要使用rootLogger配置的appender进行输出-->
	<!--    <logger name="mytest" level="info" additivity="false">-->
	<!--        <appender-ref ref="stdout"/>-->
	<!--    </logger>-->
</configuration>